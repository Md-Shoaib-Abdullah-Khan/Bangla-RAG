# ğŸ“– Bangla RAG Chatbot

**This project implements a Retrieval-Augmented Generation (RAG) based chatbot that can understand and answer both Bangla and English queries. It retrieves context from a PDF knowledge base and uses a Language Model to generate grounded and relevant answers.**  

![App](demo.png) 

---

## ğŸ“‚ **Project Structure**  
```
.
â”œâ”€â”€ app/  
â”‚   â”œâ”€â”€ api.py             # FastAPI backend for RAG queries  
â”‚   â”œâ”€â”€ main.py            # Streamlit chatbot frontend  
â”‚   â”œâ”€â”€ RAG.py             # RAG pipeline implementation  
â”‚   â”œâ”€â”€ evaluation.py      # Evaluates RAG accuracy  
â”‚   â””â”€â”€ test_cases.txt     # Test cases for evaluation
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ bangla.pdf         # Input Bangla document  
â”‚   â””â”€â”€ processed.txt      # Preprocessed text  
â”œâ”€â”€ embeddings/            # Stores vector embeddings  
â”œâ”€â”€ evaluation/  
â”‚   â””â”€â”€ test_cases.txt     # Test cases for evaluation  
â”œâ”€â”€ Preprocess.ipynb       # Preprocesses bangla.pdf â†’ processed.txt  
â”œâ”€â”€ requirements.txt       # Python dependencies  
â””â”€â”€ README.md  
```

---

## ğŸ›  **Setup Guide**  

### **1. Install Dependencies**  
```bash
git clone https://github.com/yourusername/bangla-rag-chatbot.git
cd bangla-rag-chatbot
python -m venv myenv
source myenv/bin/activate        # On Windows: myenv\\Scripts\\activate
pip install -r requirements.txt
```

### **2. Configure Environment Variables**  
Create a `.env` file:  
```env
GROQ_API_KEY="your_groq_api_key"
```

### **3. Preprocess Data**  
Run the Jupyter notebook to extract text from `bangla.pdf`:  
```bash
jupyter notebook Preprocess.ipynb
```
*(Output: `data/processed.txt`)*  

### **4. Run the Chatbot**  
**Option 1: FastAPI Backend**  
```bash
uvicorn app.api:app --reload
```
â†’ Access API docs at `http://127.0.0.1:8000/docs`  

**Option 2: Streamlit Frontend**  
```bash
streamlit run app/main.py
```
â†’ Opens chatbot at `http://localhost:8501`  

---

## ğŸ§° **Used Tools & Libraries**  
- **LLM**: Groq: `deepseek-r1-distill-llama-70b` & `gemma2-9b-it`
- **Embeddings**: HuggingFace: `l3cube-pune/bengali-sentence-similarity-sbert`  
- **Backend**: FastAPI  
- **Frontend**: Streamlit  
- **Vector DB**: Chroma (local)  
- **Evaluation**: Cosine similarity

*(List all packages in `requirements.txt`)*  

---

## ğŸ“¡ **API Documentation**  
### **POST `/query`**  
**Input**:  
```json
{"query": "à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡?"}
```  
**Output**:  
```json
{
  "answer": "à¦®à¦¾à¦®à¦¾à¦•à§‡",
}
```

---

## ğŸ” **Sample Query & Output**  
| **Query**               | **Generated Answer**                          |
|-------------------------|---------------------------------------------|
| "à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡?" | "à¦®à¦¾à¦®à¦¾à¦•à§‡" |  

---

## ğŸ“Š **Evaluation Metrics**  
Run evaluation:  
```bash
python app/evaluation.py
```  
**Metrics**:  
- **Cosine Similarity**: 0.87 (avg)  
- **BLEU Score**: 0.65  
- **Precision@K**: 0.92  

*(Example output in `evaluation/results.txt`)*  


Shoaib Khan
An AI enthusiast exploring multilingual education tools.
